{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc3a31b-2d55-4b02-8fc0-c8d7a59f2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "629c7fe4-7077-42f8-bab3-4ccdb9c23a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\Downloads\\\\amazonfinereviews\\\\Reviews.csv\")\n",
    "data = data[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bee0f634-e812-47d9-9205-fb9ab48160b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [str(i) for i in data['Text']]\n",
    "summaries  = [str(i) for i in data['Summary']]\n",
    "#target_texts  = [\"<START> \"+ str(i) + \" <END>\" for i in data['Summary']]\n",
    "\n",
    "# Define the maximum sequence lengths\n",
    "max_text_len = 100  # Adjust this as per your data\n",
    "max_summary_len = 20  # Adjust this as per your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11e0fdb2-c142-411f-97e3-f3143d63a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts and summaries\n",
    "tokenizer_text = Tokenizer()\n",
    "tokenizer_text.fit_on_texts(texts)\n",
    "tokenizer_summary = Tokenizer()\n",
    "tokenizer_summary.fit_on_texts(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbe72038-6684-4220-a146-d5223d059f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary sizes\n",
    "vocab_size_text = len(tokenizer_text.word_index) + 1\n",
    "vocab_size_summary = len(tokenizer_summary.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "634e2b39-6a8a-4a79-8859-9072d72f2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts and summaries to sequences\n",
    "text_sequences = tokenizer_text.texts_to_sequences(texts)\n",
    "summary_sequences = tokenizer_summary.texts_to_sequences(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28b61934-a1c9-4fcf-9c0f-81bce6a373bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to the same length\n",
    "encoder_input_data = pad_sequences(text_sequences, maxlen=max_text_len, padding='post')\n",
    "decoder_input_data = pad_sequences(summary_sequences, maxlen=max_summary_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c2d2ebe-8a5e-4d67-9f28-ac1e30aa002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decoder target data (shifted by one time step)\n",
    "decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "decoder_target_data[:, 0:-1] = decoder_input_data[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ae498bc-22a2-41dd-9501-33c2b3b77a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "embedding_dim = 256\n",
    "hidden_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "514a8732-936e-445a-b717-75e8645e95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(max_text_len,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size_text, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_lstm, encoder_state_h, encoder_state_c = LSTM(hidden_units, return_state=True)(encoder_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e550b02-d1dc-4682-8a23-9844796ff326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(max_summary_len,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size_summary, output_dim=embedding_dim)(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[encoder_state_h, encoder_state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c268216d-f07d-442c-8479-fb1bc205765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mechanism\n",
    "attention = Attention()([decoder_outputs, encoder_lstm])\n",
    "decoder_concat = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs, attention])\n",
    "\n",
    "# decoder_dense = Dense(vocab_size_summary, activation='softmax')\n",
    "# output = decoder_dense(decoder_concat)\n",
    "\n",
    "# Add dense layers for output\n",
    "dense_layer1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='relu'))\n",
    "dense_layer2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size_summary, activation='softmax'))\n",
    "output = dense_layer2(dense_layer1(decoder_concat))\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfc858c2-d018-426b-b52e-1348d9ddc880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 36s 4s/step - loss: 6.1956 - accuracy: 0.7121 - val_loss: 1.7882 - val_accuracy: 0.8569\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 37s 5s/step - loss: 1.5757 - accuracy: 0.8477 - val_loss: 1.3779 - val_accuracy: 0.8569\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 33s 5s/step - loss: 1.3512 - accuracy: 0.8477 - val_loss: 1.2306 - val_accuracy: 0.8569\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.2293 - accuracy: 0.8477 - val_loss: 1.1727 - val_accuracy: 0.8569\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1909 - accuracy: 0.8477 - val_loss: 1.1605 - val_accuracy: 0.8569\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1729 - accuracy: 0.8477 - val_loss: 1.1422 - val_accuracy: 0.8569\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.1539 - accuracy: 0.8477 - val_loss: 1.1273 - val_accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1262 - accuracy: 0.8477 - val_loss: 1.1038 - val_accuracy: 0.8569\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1008 - accuracy: 0.8472 - val_loss: 1.0841 - val_accuracy: 0.8569\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.0764 - accuracy: 0.8472 - val_loss: 1.0714 - val_accuracy: 0.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2088fdd9f70>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "decoder_target_data_one_hot = to_categorical(decoder_target_data, num_classes=vocab_size_summary)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data_one_hot,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2  # You can adjust the validation split as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c238756-6ca2-4828-b99a-8e2a0d6aae00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the encoder model for inference\n",
    "encoder_model = Model(encoder_inputs, [encoder_state_h, encoder_state_c])\n",
    "\n",
    "# Define the decoder model for inference\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(hidden_units,))\n",
    "decoder_states_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "#decoder_inputs_single = tf.keras.layers.Input(shape=(1,))\n",
    "#decoder_embedding_inference = Embedding(input_dim=vocab_size_summary, output_dim=embedding_dim)(decoder_inputs)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_input)\n",
    "\n",
    "decoder_states_inference = [state_h, state_c]\n",
    "\n",
    "attention_inference = Attention()([decoder_outputs, encoder_lstm])\n",
    "decoder_concat_inference = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs, attention_inference])\n",
    "\n",
    "decoder_outputs_inference = decoder_dense(decoder_concat_inference)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_input, [decoder_outputs] + decoder_states_inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abfd4af6-90e4-43b6-9d7f-c9fe49962381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a summary for an input text\n",
    "def generate_summary(input_text):\n",
    "    # Tokenize and pad the input text\n",
    "    input_seq = tokenizer_text.texts_to_sequences([input_text])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "    # Encode the input text using the encoder model\n",
    "    encoder_states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Initialize the decoder input with index 0 (assuming index 0 corresponds to the padding token)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    stop_condition = False\n",
    "    summary = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + encoder_states)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tokenizer_summary.index_word.get(sampled_token_index, None)\n",
    "\n",
    "        if sampled_token is not None and sampled_token != '<eos>' and len(summary) < max_summary_len - 1:\n",
    "            summary.append(sampled_token)\n",
    "\n",
    "        if sampled_token == '<eos>' or len(summary) >= max_summary_len - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    return ' '.join(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31cb0de3-3d06-4c5f-bd4f-53cc24cb0049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Generated Summary: pack pack pack pack pack pack pack pack pack pack pack pack pack pack pack pack pack pack pack\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_text = texts[7]\n",
    "print(input_text)\n",
    "generated_summary = generate_summary(input_text)\n",
    "print(\"Generated Summary:\", generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef40a6-4510-4e69-96dd-dbfad3583da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
