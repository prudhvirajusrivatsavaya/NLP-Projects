{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5a6b6-ae8e-48be-a298-0b0f05360a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting the implementation try understanding this article\n",
    "# https://www.linkedin.com/pulse/understanding-batch-normalization-layer-group-implementing-pasha-s/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b11761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359352d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>super!</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>useless product</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price Rate  \\\n",
       "0  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "1  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "2  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "3  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
       "4  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "\n",
       "            Review                                            Summary  \\\n",
       "0           super!  great cooler excellent air flow and for this p...   \n",
       "1          awesome              best budget 2 fit cooler nice cooling   \n",
       "2             fair  the quality is good but the power of air is de...   \n",
       "3  useless product                  very bad product its a only a fan   \n",
       "4             fair                                      ok ok product   \n",
       "\n",
       "  Sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset-SA.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5af880a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180388, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Review','Sentiment']]\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b3a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = [str(text) for text in df['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1747a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the label encoder on the data and transform the data\n",
    "encoded_data = label_encoder.fit_transform(df['Sentiment'])\n",
    "df['Sentiment_Coded'] = encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b8b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True,\n",
    "    split=' ',\n",
    "    char_level=False,\n",
    "    #oov_token=\"<OOV>\",\n",
    "    analyzer=None,\n",
    "    )\n",
    "tokenizer.fit_on_texts(df['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15b5a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = max([len(i.split()) for i in df['Review']])\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fda0718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment_Coded'], test_size=0.2, random_state=42, stratify=df['Sentiment_Coded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b588d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test  = list(x_train), list(x_test), list(y_train), list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f02a0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test =  tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a56a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "pad_sequence_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
    "pad_sequence_test = pad_sequences(sequences_test, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dae81b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.index_word)\n",
    "output_size = len(df['Sentiment'].unique())\n",
    "vocab_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcc6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebefb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 22, 128)           169088    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 22, 256)           263168    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 22, 256)           1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 256)               394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 847555 (3.23 MB)\n",
      "Trainable params: 846339 (3.23 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, LSTM, Bidirectional, Dropout, LayerNormalization, BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_sequence_length,)))\n",
    "model.add(Embedding(input_dim=vocab_size+1, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(units=128)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(output_size,activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a00dda4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 317s 2s/step - loss: 0.5224 - accuracy: 0.8636 - val_loss: 0.5691 - val_accuracy: 0.8159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b5b1064610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pad_sequence_train, y_train_categorical, epochs = 1, batch_size = 1028, validation_data=(pad_sequence_test, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a580f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= x_test[0]\n",
    "sequences_inference = tokenizer.texts_to_sequences([text])\n",
    "padded_sequences_inference = pad_sequences(sequences_inference,maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e808de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 33, 6]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09bae2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.27361867, 0.26205122, 0.69570553]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_sequences_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da8d5e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.27361867, 0.26205122, 0.69570553]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_sequences_inference[0].reshape(1,22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede79688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
