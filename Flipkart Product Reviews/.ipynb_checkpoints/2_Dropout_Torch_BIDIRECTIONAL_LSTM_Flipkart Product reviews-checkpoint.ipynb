{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cb466-8ac0-463b-ae58-5e0944216a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting the implementation try understanding this article\n",
    "# https://www.linkedin.com/pulse/understanding-batch-normalization-layer-group-implementing-pasha-s/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b11761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359352d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>super!</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>useless product</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price Rate  \\\n",
       "0  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "1  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "2  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "3  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
       "4  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "\n",
       "            Review                                            Summary  \\\n",
       "0           super!  great cooler excellent air flow and for this p...   \n",
       "1          awesome              best budget 2 fit cooler nice cooling   \n",
       "2             fair  the quality is good but the power of air is de...   \n",
       "3  useless product                  very bad product its a only a fan   \n",
       "4             fair                                      ok ok product   \n",
       "\n",
       "  Sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4   neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset-SA.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5af880a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180388, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Review','Sentiment']]\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b3a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = [str(text) for text in df['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1747a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the label encoder on the data and transform the data\n",
    "encoded_data = label_encoder.fit_transform(df['Sentiment'])\n",
    "df['Sentiment_Coded'] = encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0a8df5-1eda-4062-bab2-7a2e18438722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True,\n",
    "    split=' ',\n",
    "    char_level=False,\n",
    "    #oov_token=\"<OOV>\",\n",
    "    analyzer=None,\n",
    "    )\n",
    "tokenizer.fit_on_texts(df['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15b5a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = max([len(i.split()) for i in df['Review']])\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fda0718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment_Coded'], test_size=0.2, random_state=42, stratify=df['Sentiment_Coded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b588d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test  = list(x_train), list(x_test), list(y_train), list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ce3cac-d568-4080-99c8-d398a78c37c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144310, 36078, 144310, 36078)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f40e9a-22b3-49f9-aa2c-28b40c5cdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test =  tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95524508-a0f9-428b-b43b-5cec7e41f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "pad_sequence_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
    "pad_sequence_test = pad_sequences(sequences_test, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30214114-e71f-4b27-8bef-80b2da863038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.index_word)\n",
    "output_size = len(df['Sentiment'].unique())\n",
    "vocab_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b35e057-43be-4fee-853d-1de73a05c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_classes = 31\n",
    "one_hot_labels_y_train = np.eye(num_classes)[y_train]\n",
    "one_hot_labels_y_test = np.eye(num_classes)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f90231-8a0e-46ae-9976-92f5f8aea3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                        # root package\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, sequences,labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.sequences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf2c2ef5-60ce-41b1-888b-63c46947eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(pad_sequence_train, one_hot_labels_y_train)\n",
    "test_dataset = TextClassificationDataset(pad_sequence_test,one_hot_labels_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93f32fb-9d5e-4395-8c9e-df84ab012ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle= True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b450c67c-bb46-4ea5-b821-42e52a25ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class BLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(BLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.blstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.dropout_1 = nn.Dropout(0.5)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim*2)\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim*2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(128)\n",
    "        ])\n",
    "        self.fc = nn.Linear(128,num_classes)\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out, _ = self.blstm(embedded)\n",
    "        dropout_1=self.dropout_1(out)\n",
    "        norm = self.layer_norm(out)\n",
    "        out = torch.cat((norm[:, -1, :hidden_dim], norm[:, 0, hidden_dim:]), dim=1)\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac1bf470-fb29-4c6f-a82a-c5cd7c7a21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "vocab_size = 10000  # Size of your vocabulary\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "hidden_dim = 64  # Dimension of hidden states\n",
    "num_classes = 3  # Number of classes in your classification problem\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f85a7bb7-2b79-4eda-b4e6-e010cb90394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLSTMModel(\n",
      "  (embedding): Embedding(10000, 100)\n",
      "  (blstm): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
      "  (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the BLSTM model\n",
    "model = BLSTMModel(vocab_size, embedding_dim, hidden_dim, num_classes)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bd6b467-7fda-4c31-bd96-f532fad08a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "885a9eaa-003b-4971-889a-fcaad1650824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, torch.argmax(labels, axis=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf8f98a-2e2d-4dee-a3c3-2beff326e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.9116358999944565\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, axis=1)).sum().item()\n",
    "\n",
    "accuracy = correct/total\n",
    "print(\"Test Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eee536-6375-434f-9e94-6b57c861ceef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75de45-b3dc-4a4e-8db4-198ae7d73f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0851adb-1296-485b-a0df-7ca9932613fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fba801-ca3d-417e-bb5f-3a4616a1903c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
